info:
  name: '@project.parent.name@'
  version: '@project.version@'

server:
  address: 0.0.0.0
  servlet:
    context-path: /
  port: 6060

management:
  endpoints.web:
    exposure.include: '*'
  health:
    jms:
      enabled: false
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
    binders:
      enabled: true
  server:
    address: 0.0.0.0
    port: 6061
  metrics:
    export:
      prometheus:
        enabled: true
  endpoint:
    metrics:
      enable: true
    prometheus:
      enable: true
    health:
      show-details: always
      probes:
        enabled: true

spring:
  cloud:
    stream:
      function:
        definition: processAvro;processProto;moveData
      bindings:
        processProto-in-0:
          destination: OrdersInput-proto
        processProto-in-1:
          destination: EnabledCustomer-proto
        processProto-out-0:
          destination: OrdersOutput-proto
        processAvro-in-0:
          destination: OrdersInput-avro
        processAvro-in-1:
          destination: EnabledCustomer-proto
        processAvro-out-0:
          destination: OrdersOutput-avro
        moveData-in-0:
          destination: CustomerDetails-proto
        moveData-out-0:
          destination: EnabledCustomer-proto
      kafka:
        bindings:
          moveData-in-0:
            consumer:
              value-serde: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
              configuration:
                derive.type: true
          moveData-out-0:
            consumer:
              value-serde: io.confluent.kafka.serializers.protobuf.KafkaProtobufSerializer
              configuration:
                derive.type: true
        streams:
          binder:
            deserialization-exception-handler: sendtodlq
            functions:
              processProto.applicationId: spring-cloud-kafka-streams-stream-globalktable-processProto
              processAvro.applicationId: spring-cloud-kafka-streams-stream-globalktable-processAvro
            configuration:
              state.dir: state-store
              acceptable.recovery.lag: 0
              schema.registry.url: http://localhost:8081
          bindings:
            processProto-in-0:
              consumer:
                value-serde: io.confluent.kafka.streams.serdes.protobuf.KafkaProtobufSerde
                configuration:
                  derive.type: true
            processProto-in-1:
              consumer:
                value-serde: io.confluent.kafka.streams.serdes.protobuf.KafkaProtobufSerde
                configuration:
                  derive.type: true
            processProto-out-0:
              producer:
                value-serde: io.confluent.kafka.streams.serdes.protobuf.KafkaProtobufSerde
                configuration:
                  derive.type: true
            processAvro-in-0:
              consumer:
                value-serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
                configuration:
                  specific.avro.reader: true
            processAvro-in-1:
              consumer:
                value-serde: io.confluent.kafka.streams.serdes.protobuf.KafkaProtobufSerde
                configuration:
                  derive.type: true
            processAvro-out-0:
              producer:
                value-serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
                configuration:
                  specific.avro.reader: true
        binder:
          configuration:
            heartbeat.interval.ms: 10000
            max.poll.records: 5000

logging.level:
  root: info
  debug: false
